\documentclass[11pt,twocolumn]{article}
    \usepackage{amsmath}
    \usepackage{mathtools}
    \usepackage{cleveref}
    \usepackage{pgfplots}
    \usepackage{graphicx}
    \usepackage{wrapfig}
    \usepackage{fancyref}
    \usepackage{amssymb}
    \usepackage{subfig}
    \usepackage{float}
    
    \usepackage[justification=RaggedRight, singlelinecheck=false, font={footnotesize}]{caption}
    \usepackage[portuguese]{babel}
    \usepackage[title,titletoc,toc]{appendix}
    
    
    \usepackage{lipsum}
    \usepackage{blindtext}
    \usepackage{fontspec}
    \begin{document}
    \pagenumbering{arabic}
    \bibliographystyle{plain}
    \title{
        \textnormal{
        \LARGE Universidade de Lisboa - Instituto Superior Técnico\\
        \Large Licenciatura em Engenharia Informática e de Computadores\\
        \Large Inteligência Artificial
    \\}
        \LARGE2º Projeto - Grupo 22
        \vspace{-1ex}
        }
    \author{Gonçalo Marques,
        \texttt{84719}
        \and
        Manuel Sousa,
        \texttt{84740}
    }
    \date{	\vspace{-1ex}
            \vspace{-4ex}
        }
    \maketitle
    
    \section*{P1}
    
    Começámos por elaborar um conjunto de features a aplicar sobre as palavras. De inicio contruimos features básicas que verificassem o numero de vogais e consoantes de uma palavra, o numero de acentos, etc. O primeiro objetivo passava apenas por estudar
    o comportamento do avaliador, e durante este processo, facilmente concluimos que quanto mais unico fosse o output da feature em relação à palavra recebida, menor seria o erro.
    
    
    \begin{table}[htbp]
        \centering
        \caption{Analise individual dos erros de cada feature}
        \label{my-label}
        \begin{tabular}{|l|c|c|}
        \hline
        \multicolumn{1}{|r|}{}                                      & \textbf{Teste 1} & \textbf{Teste 2}                    \\ \hline
        [F1] N Acentos & 0.666   & 0.231 \\ \hline
        [F2] N Vogais Par & 0.264   & 0.231 \\ \hline
        [F3] N Vogais & 0.264   & 0.348 \\ \hline
        [F4] N Consoantes   & 0.264  & 0.231      \\ \hline
        [F5] Palavras Repetidas   & 0.264  & 0.231      \\ \hline
        [F6] Palavra Par   & 0.231  & 0.231      \\ \hline
        [F7] Soma ASCII                             & 0.130            & 0.122                                \\ \hline
        [F8] Hash                             & 0.0              & 0.0                                 \\ \hline
        \end{tabular}
        \end{table}
    \par

    Podemos observar que a função que soma o ASCII dos caracteres
    constituintes da palavra, tem um erro muito reduzido visto que o output dado pela feature será sempre único, menos quando palavras diferentes são constituidas pelos mesmos caracteres. 
    Assim, uma função que der um output unico para cada palavra recebida iria dar um erro ainda mais baixo. Criámos uma função que gera um inteiro único para uma palavra (Hash), e desta maneira conseguimos obter uma percentagem de erro de 0\%.
    
    \begin{table}[htbp]
        \centering
        \caption{Analise coletiva dos erros com várias features}
        \label{my-label}
        \begin{tabular}{|l|c|c|}
        \hline
        \multicolumn{1}{|r|}{}                                      & \textbf{Teste 1} & \textbf{Teste 2}                    \\ \hline
        [F5] + [F6] & 0.231 & 0.231 \\ \hline
        [F5] + [F6] + [F7]     & 0.077  & 0.077                   \\ \hline
        [F4] + [F5] + [F7] + [F8]   & 0.0              & 0.0                                 \\ \hline
        [F3] + [F4] + [F7]   & 0.064             & 0.064                                 \\ \hline
        [F3] + [F4] + [F7] + [F8]   & 0.0          & 0.0                                 \\ \hline
        \end{tabular}
        \end{table}
    \par  
    Por observação à tabela concluimos que a utilização de várias features produz um erro mais baixo, que usar features individuais. 
    Observamos tambem que a feature 8 é predominante, visto que a sua presença é suficiente para dar erro de 0\%.

\section*{P2}

Nesta secção usámos dois métodos de regressão não-linear: Epsilon-Support Vector Regression (SVR) e KernelRidge com kernel de Radial-basis function (KRR).
Usando validação cruzada (K-fold cross validation com um K=13), concluímos que as precisões de cada um destes métodos em ambos os testes são, respetivamente, (-0.17; -62.50) e (-0.12; -37.23).
A grande disparidade de precisão entre ambos os testes deve-se ao facto de os dados apresentados estarem dispostos exatamente de acordo com uma função de 3º grau no primeiro teste,
ao contrário do 2º teste, em que os valores estão muito mais dispersos.
Os parâmetros foram ajustados de maneira a modelarem mais precisamente os dados apresentados em ambas as situações.
Concluímos então que o método KRR tem melhor precisão no caso apresentado.

\section*{P3}

As imagens seguintes ilustram a maneira como o agente se movimenta pelos ambientes 1 e 2, incluíndo uma representação gráfica dos mesmos:
	*inserir imagem Trajetória 1*
	*inserir imagem Trajetória 2*

A função de recompensa, f(x) = y é a seguinte para ambas as trajetórias *inserir imagem Piecewise 1*, em que x corresponde ao estado 
em que o agente se encontra e y é a recompensa de executar uma ação nesse estado.\par

\end{document}
